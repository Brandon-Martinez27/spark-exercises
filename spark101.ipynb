{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "following Spark API Lession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spark session:\n",
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **1. Create a spark data frame that contains your favorite programming languages.**\n",
    "\n",
    "- The name of the column should be `language`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[lanugage: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df = pd.DataFrame({'lanugage': ['Python', 'SQL', 'Java', 'HTML', 'C++']})\n",
    "sp_df = spark.createDataFrame(pd_df)\n",
    "sp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- lanugage: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like df.info()\n",
    "sp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df.count(), len(sp_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|lanugage|\n",
      "+--------+\n",
      "|  Python|\n",
      "|     SQL|\n",
      "|    Java|\n",
      "|    HTML|\n",
      "|     C++|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **2. Load the `mpg` dataset as a spark dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "\n",
    "  ```The 1999 audi a4 has a 4 cylinder engine.```\n",
    "  for each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|string                                   |\n",
      "+-----------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 6 cylinder engine.|\n",
      "+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "mpg.select(concat(lit('The '), \n",
    "                  mpg.year,\n",
    "                  lit(' '),\n",
    "                  mpg.manufacturer,\n",
    "                  lit(' '),\n",
    "                  mpg.model, \n",
    "                  lit(' has a '), \n",
    "                  mpg.cyl, \n",
    "                  lit(' cylinder engine.')).alias('string')).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform the `trans` column so that it only contains either `manual` or `auto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class| trans|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|  auto|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|manual|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|manual|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|  auto|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|  auto|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "\n",
    "mpg.select('*', \n",
    "           regexp_extract('trans',\n",
    "                         r'^(\\w+)', 1).alias('trans')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3. Load the `tips` dataset as a spark dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.createDataFrame(data('tips'))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, avg\n",
    "\n",
    "\n",
    "round(tips.filter(tips.smoker == 'Yes').count() / tips.count() * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    tip_percentage|\n",
      "+------------------+\n",
      "|5.9446733372572105|\n",
      "|16.054158607350097|\n",
      "|16.658733936220845|\n",
      "| 13.97804054054054|\n",
      "|14.680764538430255|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = tips.select('*', (tips.tip/tips.total_bill * 100).alias('tip_percentage'))\n",
    "tips.select('tip_percentage').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------------------+\n",
      "|   sex|smoker|avg(tip_percentage)|\n",
      "+------+------+-------------------+\n",
      "|  Male|    No|  16.06687151291298|\n",
      "|  Male|   Yes| 15.277117520248513|\n",
      "|Female|    No| 15.692097076918358|\n",
      "|Female|   Yes|  18.21503526994103|\n",
      "+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('sex', 'smoker').agg(avg(tips.tip_percentage)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **4. Use the seattle weather dataset referenced in the lesson to answer the questions below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "sw = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "sw = spark.createDataFrame(sw)\n",
    "sw.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the temperatures to farenheight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n",
      "|        temp_max_f|temp_min_f|\n",
      "+------------------+----------+\n",
      "|55.040000000000006|      41.0|\n",
      "|             51.08|     37.04|\n",
      "|             53.06|     44.96|\n",
      "|             53.96|     42.08|\n",
      "|48.019999999999996|     37.04|\n",
      "+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fahrenheit = (Celsius * 9/5) + 32\n",
    "sw.select((sw.temp_max * (9/5) + 32).alias('temp_max_f'),\n",
    "          (sw.temp_min * (9/5) + 32).alias('temp_min_f')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc, sum, max\n",
    "from pyspark.sql.functions import month, year, quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|month|       avg_rainfall|\n",
      "+-----+-------------------+\n",
      "|   11|  5.354166666666667|\n",
      "|   12|  5.021774193548388|\n",
      "|    3|  4.888709677419355|\n",
      "|   10|  4.059677419354839|\n",
      "|    1| 3.7580645161290316|\n",
      "|    2|  3.734513274336283|\n",
      "|    4|  3.128333333333333|\n",
      "|    9| 1.9624999999999997|\n",
      "|    5| 1.6733870967741935|\n",
      "|    8| 1.3201612903225806|\n",
      "|    6| 1.1075000000000002|\n",
      "|    7|0.38870967741935486|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(avg(\"precipitation\").alias(\"avg_rainfall\"))\n",
    "    .sort(desc(\"avg_rainfall\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|        total_wind|\n",
      "+----+------------------+\n",
      "|2012|1244.6999999999998|\n",
      "|2014|1236.5000000000005|\n",
      "|2015|            1153.3|\n",
      "|2013|1100.8000000000002|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sw.withColumn('year', year('date'))\n",
    "    .groupBy('year')\n",
    "    .agg(sum('wind').alias('total_wind'))\n",
    "    .sort(desc('total_wind'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|weather|freq_weather|\n",
      "+-------+------------+\n",
      "|    sun|         714|\n",
      "|    fog|         411|\n",
      "|   rain|         259|\n",
      "|drizzle|          54|\n",
      "|   snow|          23|\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sw.withColumn('weather', sw.weather)\n",
    "    .groupBy('weather')\n",
    "    .agg(count('weather').alias('freq_weather'))\n",
    "    .sort(desc('freq_weather'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+------------------+\n",
      "|month(date)|year(date)|     avg(temp_min)|     avg(temp_max)|\n",
      "+-----------+----------+------------------+------------------+\n",
      "|          7|      2013|13.981481481481483|26.585185185185193|\n",
      "|          7|      2014|14.400000000000002|            27.092|\n",
      "+-----------+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sw.filter(((year('date') == '2013') \n",
    "        | (year('date') == '2014')) \n",
    "        & (month('date') == '07'))\n",
    "        .where(sw.weather == 'sun')\n",
    "        .groupBy(month('date'), year('date'))\n",
    "        .agg(avg('temp_min'), avg('temp_max'))\n",
    "        .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         pct_rainy|\n",
      "+------------------+\n",
      "|6.2970568104038325|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q1: 01-03, q2: 04-06, q3: 07-09, q4: 10-12\n",
    "rainy_days = (\n",
    "    sw.withColumn('2015', year('date'))\n",
    "    .filter(year('date') == '2015').alias('2015')\n",
    "    .filter((month('date') == '07')\n",
    "           |(month('date') == '08')\n",
    "           |(month('date') == '09'))\n",
    "    .groupBy('2015')\n",
    "    .agg(count(sw.weather == 'rain').alias('num_days'))\n",
    ")\n",
    "\n",
    "rainy_days.select((rainy_days.num_days / sw.count() * 100).alias('pct_rainy')).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby year, agg by pct_rained\n",
    "# filter by days_rained/total_days AS pct_rained\n",
    "\n",
    "days_rained = sw.filter(col('precipitation') != 0)\n",
    "total_days = sw\n",
    "\n",
    "#days_rained/total_days\n",
    "\n",
    "#sw.groupBy(year('date')).agg(count(days_rained/total_days)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "|2012-01-09|          4.3|     9.4|     5.0| 3.4|   rain|\n",
      "|2012-01-10|          1.0|     6.1|     0.6| 3.4|   rain|\n",
      "|2012-01-14|          4.1|     4.4|     0.6| 5.3|   snow|\n",
      "|2012-01-15|          5.3|     1.1|    -3.3| 3.2|   snow|\n",
      "|2012-01-16|          2.5|     1.7|    -2.8| 5.0|   snow|\n",
      "|2012-01-17|          8.1|     3.3|     0.0| 5.6|   snow|\n",
      "|2012-01-18|         19.8|     0.0|    -2.8| 5.0|   snow|\n",
      "|2012-01-19|         15.2|    -1.1|    -2.8| 1.6|   snow|\n",
      "|2012-01-20|         13.5|     7.2|    -1.1| 2.3|   snow|\n",
      "|2012-01-21|          3.0|     8.3|     3.3| 8.2|   rain|\n",
      "|2012-01-22|          6.1|     6.7|     2.2| 4.8|   rain|\n",
      "|2012-01-24|          8.6|    10.0|     2.2| 5.1|   rain|\n",
      "|2012-01-25|          8.1|     8.9|     4.4| 5.4|   rain|\n",
      "|2012-01-26|          4.8|     8.9|     1.1| 4.8|   rain|\n",
      "|2012-01-29|         27.7|     9.4|     3.9| 4.5|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sw.withColumn(\n",
    "    'rained', expr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
